from __future__ import annotations

import concurrent.futures
import hashlib
import json
import re
import threading
import time
from datetime import datetime
from io import BytesIO
from typing import Any, Dict, List, Optional

import openpyxl
import streamlit as st
from dateutil import tz

from src.config import MODEL_NAME, hash_prompt, md5_text, to_json
from src.evaluator import Evaluator
from src.report_writer import render_report

SCOPES = []

STEP1_SCHEMA_HINT = {
    "company_name": "string",
    "one_line_summary": "string",
    "overall_summary": "string (ì¢…í•© í‰ê°€ ìš”ì•½)",
    "logic_score": "number 0-100",
    "pass_gate": "boolean (logic_score >= 80)",
    "perspective_scores": {
        "critical": "number 0-100",
        "neutral": "number 0-100",
        "positive": "number 0-100",
    },
    "item_evaluations": {
        "ë¬¸ì œì •ì˜": {"score": "number 0-10", "comment": "string", "feedback": "string"},
        "ì†”ë£¨ì…˜&ì œí’ˆ": {"score": "number 0-10", "comment": "string", "feedback": "string"},
        "ì‹œì¥ê·œëª¨&ë¶„ì„": {"score": "number 0-10", "comment": "string", "feedback": "string"},
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": {"score": "number 0-10", "comment": "string", "feedback": "string"},
        "ê²½ìŸë¶„ì„": {"score": "number 0-10", "comment": "string", "feedback": "string"},
        "ì„±ì¥ì „ëµ": {"score": "number 0-10", "comment": "string", "feedback": "string"},
        "ì£¼ìš” ì¸ë ¥&íŒ€": {"score": "number 0-10", "comment": "string", "feedback": "string"},
        "ì¬ë¬´ê³„íš": {"score": "number 0-10", "comment": "string", "feedback": "string"},
    },
    "item_scores": {"market": "number 0-10", "team": "number 0-10", "product": "number 0-10"},
    "strengths": {"market": "list[str]", "team": "list[str]", "product": "list[str]"},
    "weaknesses": {"market": "list[str]", "team": "list[str]", "product": "list[str]"},
    "red_flags": "list[str]",
    "cost_estimate": {"llm_calls": "number", "tokens": "number", "usd": "number"},
}

STEP2_SCHEMA_HINT = {
    "stage_label": "string (Seed/Pre-Seed/Series A/Series B+/Unknown)",
    "industry_label": "string (SaaS/Commerce/Bio-Healthcare/DeepTech/Other)",
    "stage_score": "number 0-10",
    "industry_score": "number 0-10",
    "bm_score": "number 0-10",
    "axis_comments": {"stage": "string", "industry": "string", "bm": "string"},
    "validation_questions": {"stage": "list[str]", "industry": "list[str]", "bm": "list[str]"},
    "cost_estimate": {"llm_calls": "number", "tokens": "number", "usd": "number"},
}

SHEET_COLUMNS = [
    "timestamp(KST)",
    "file_name",
    "company_name",
    "company_description",
    "score_critical",
    "score_neutral",
    "score_positive",
    "recommendation_critical",
    "recommendation_neutral",
    "recommendation_positive",
    "overall_summary",
    "item_evaluations_json",
    "strengths_json",
    "weaknesses_json",
    "red_flags_json",
    "axis_scores_json",
    "axis_comments_json",
    "validation_questions_json",
    "final_verdict",
]

STATUS_PENDING = "ëŒ€ê¸°"
STATUS_RUNNING = "ì§„í–‰ì¤‘"
STATUS_SKIPPED = "ìŠ¤í‚µ"
STATUS_DONE = "ì™„ë£Œ"
STATUS_FAILED = "ì‹¤íŒ¨"

ITEM_KEYS = [
    "ë¬¸ì œì •ì˜",
    "ì†”ë£¨ì…˜&ì œí’ˆ",
    "ì‹œì¥ê·œëª¨&ë¶„ì„",
    "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸",
    "ê²½ìŸë¶„ì„",
    "ì„±ì¥ì „ëµ",
    "ì£¼ìš” ì¸ë ¥&íŒ€",
    "ì¬ë¬´ê³„íš",
]

PROMPT_APPENDIX = (
    "ì¶”ê°€ ì§€ì‹œì‚¬í•­:\n"
    "1) Step1/Step2 JSONì€ ë°˜ë“œì‹œ ìŠ¤í‚¤ë§ˆ íŒíŠ¸ì— ë§ì¶° ì¶œë ¥í•œë‹¤.\n"
    "2) í•­ëª©ë³„ í‰ê°€ëŠ” ë‹¤ìŒ í•­ëª©ìœ¼ë¡œ ê³ ì •í•œë‹¤: "
    "ë¬¸ì œì •ì˜, ì†”ë£¨ì…˜&ì œí’ˆ, ì‹œì¥ê·œëª¨&ë¶„ì„, ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸, ê²½ìŸë¶„ì„, ì„±ì¥ì „ëµ, ì£¼ìš” ì¸ë ¥&íŒ€, ì¬ë¬´ê³„íš.\n"
    "3) item_evaluationsì— ê° í•­ëª©ë³„ score(0-10), comment, feedbackì„ í¬í•¨í•œë‹¤.\n"
    "4) strengths/weaknessesëŠ” íˆ¬ìì ê´€ì ì—ì„œ ì—„ê²©í•˜ê²Œ ì‘ì„±í•œë‹¤.\n"
    "5) overall_summary(ì¢…í•© í‰ê°€ ìš”ì•½)ë¥¼ ë°˜ë“œì‹œ í¬í•¨í•œë‹¤.\n"
    "6) item_evaluationsì˜ commentëŠ” 5~8ë¬¸ì¥, feedbackì€ 4~5ë¬¸ì¥ìœ¼ë¡œ ì‘ì„±í•œë‹¤. "
    "ì „ë¬¸ VC ë©”ëª¨ì²˜ëŸ¼ ê·¼ê±°(ìˆ«ì/ì§€í‘œ/ì‚¬ì‹¤)ì™€ ë…¼ë¦¬ë¥¼ í¬í•¨í•˜ê³ , "
    "ì‹¤í–‰ ê°€ëŠ¥í•œ ê°œì„  ê¶Œê³ ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•œë‹¤.\n"
    "7) Step2ì—ëŠ” stage_labelê³¼ industry_labelì„ í¬í•¨í•œë‹¤. "
    "stage_labelì€ Seed/Pre-Seed/Series A/Series B+/Unknown ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•œë‹¤. "
    "industry_labelì€ SaaS/Commerce/Bio-Healthcare/DeepTech/Other ì¤‘ í•˜ë‚˜ë¥¼ ì‚¬ìš©í•œë‹¤.\n"
    "8) ì ìˆ˜ ì‚°ì •ì€ ë…¼ë¦¬ì„±ê³¼ ê·¼ê±° ìˆ˜ì¤€ì— ë”°ë¼ ë³´ìˆ˜ì ìœ¼ë¡œ ë¶€ì—¬í•˜ë˜, "
    "ê´€ì ë³„ ì°¨ì´ê°€ ë“œëŸ¬ë‚˜ë„ë¡ ì‘ì„±í•œë‹¤.\n"
)

BASE_PROMPT = """# ROLE (FIXED)

ë„ˆëŠ” ì‹¤ë¦¬ì½˜ë°¸ë¦¬ì—ì„œ ê°€ì¥ ê¹Œë‹¤ë¡­ê¸°ë¡œ ìœ ëª…í•œ ì‹œë‹ˆì–´ íˆ¬ì ì‹¬ì‚¬ì—­ì´ë‹¤. IR ìë£Œì— ë‚˜ì˜¤ëŠ” ê°ì„±ì ì¸ í˜¸ì†Œë‚˜ ë¯¸ë ¤í•œ ë¬¸êµ¬ì— í˜„í˜¹ë˜ì§€ ë§ˆë¼. ëª¨ë“  ì£¼ì¥ì— ëŒ€í•´ 'ê·¸ê²Œ ì§„ì§œì•¼?(Is it true?)', 'ê·¸ë˜ì„œ ì–´ì©Œë¼ê³ ?(So what?)', 'ë„ˆë„¤ë§Œ í•  ìˆ˜ ìˆì–´?(Why you?)'ë¼ëŠ” ì„¸ ê°€ì§€ ê´€ì ì—ì„œ ë¹„íŒì ìœ¼ë¡œ ê²€í† í•œ ë’¤, ë§¤ìš° ë³´ìˆ˜ì ì¸ ì ìˆ˜ë¥¼ ë¶€ì—¬í•´ë¼.
ë„ˆëŠ” ì´ ì‚¬ì—…ì´ ì•ˆ ë  ì´ìœ ë¥¼ ì°¾ëŠ” ë¹„ê´€ì ì¸ ì‹¬ì‚¬ì—­ì´ë‹¤. í™”ë ¤í•œ ìˆ˜ì‹ì–´ëŠ” ë¬´ì‹œí•˜ê³ , ì˜¤ì§ **ì…ì¦ëœ ë°ì´í„°(Evidence-backed Data)**ì™€ ì¸ê³¼ê´€ê³„ì˜ ì—„ê²©í•¨ë§Œ ë¯¿ëŠ”ë‹¤


IR ìë£Œì— ë‚˜ì˜¤ëŠ” ê°ì„±ì  í˜¸ì†Œ, ë¯¸ë ¤í•œ ë¬¸êµ¬, ë¹„ì „ ì¤‘ì‹¬ ìˆ˜ì‹ì–´ì—ëŠ” ì ˆëŒ€ í˜„í˜¹ë˜ì§€ ë§ˆë¼.
ëª¨ë“  ì£¼ì¥ì— ëŒ€í•´ ë°˜ë“œì‹œ ì•„ë˜ 3ê°€ì§€ ì§ˆë¬¸ìœ¼ë¡œë§Œ íŒë‹¨í•œë‹¤.

1) Is it true?  â†’ ì…ì¦ëœ ë°ì´í„°ê°€ ìˆëŠ”ê°€
2) So what?     â†’ íˆ¬ììì—ê²Œ ì˜ë¯¸ ìˆëŠ”ê°€
3) Why you?     â†’ ì™œ ì´ íŒ€ë§Œ ê°€ëŠ¥í•œê°€

ì…ì¦ë˜ì§€ ì•Šì€ ì£¼ì¥ì€ ê°€ì„¤ë¡œ ê°„ì£¼í•˜ê³  ê°ì í•˜ë¼.
ë…¼ë¦¬ì  ë¹„ì•½ì€ ê´€ë¦¬ë˜ì§€ ì•Šìœ¼ë©´ ê°•í•˜ê²Œ ê°ì í•˜ë¼.
ë„ˆëŠ” ë¹„ê´€ì ì¸ ì‹¬ì‚¬ì—­ì´ë©°, ì˜¤ì§ Evidence-backed Dataì™€ ì¸ê³¼ê´€ê³„ì˜ ì—„ê²©í•¨ë§Œ ì‹ ë¢°í•œë‹¤.

---

# CONSTITUTION (ABSOLUTE)

ì•„ë˜ ì œê³µë˜ëŠ” â€œIR í‰ê°€ ê¸°ì¤€ ë¬¸ì„œâ€ë¥¼ í•˜ë‚˜ì˜ í—Œë²•ì²˜ëŸ¼ ì ˆëŒ€ì ìœ¼ë¡œ ë”°ë¥¸ë‹¤.
ì„ì˜ë¡œ í•´ì„ì„ í™•ì¥í•˜ê±°ë‚˜ ê¸°ì¤€ì„ ì™„í™”í•˜ì§€ ì•ŠëŠ”ë‹¤.

---

# HARD RULES (NON-NEGOTIABLE)

1. ì¶œë ¥ì€ JSONê³¼ ë§ˆí¬ë‹¤ìš´íŒŒì¼ë¡œ í•˜ê³  ë¯¸ë¦¬ë³´ê¸° ì¶œë ¥í•œë‹¤.
2. JSONì€ ì§€ì •ëœ ìŠ¤í‚¤ë§ˆì™€ ì •í™•íˆ ì¼ì¹˜í•´ì•¼ í•œë‹¤.
3. ê°•ì /ì•½ì ì€ ë°˜ë“œì‹œ íˆ¬ìì ê´€ì ì—ì„œ ì‘ì„±í•œë‹¤.
4. ì ìˆ˜ëŠ” ëƒ‰ì •í•˜ê²Œ ë¶€ì—¬í•˜ë©°, ì˜ì‹¬ë˜ëŠ” ì§€ì ë§ˆë‹¤ ê¹ëŠ”ë‹¤.

---

# INPUT SCOPE

- ì…ë ¥: IR full-text Markdown (.md)

---

# OVERALL GOAL

â€œì´ íšŒì‚¬ëŠ” ë…¼ë¦¬ì ìœ¼ë¡œ ì„¤ë“ë˜ë©°,
í•´ë‹¹ ì‚°ì—… Ã— íˆ¬ìë‹¨ê³„ Ã— ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸ ì¡°ê±´ì—ì„œ
í‰ê·  ëŒ€ë¹„ ìš°ìˆ˜í•œê°€?â€

---

## [STAGE 1] IR ë…¼ë¦¬ì„±Â·ì¶©ì‹¤ì„± í‰ê°€ (GATE / ABSOLUTE)

- ì´ì : 0â€“100
- ì»·íŠ¸ë¼ì¸: **80ì **
- 80ì  ë¯¸ë§Œì´ë©´:
  â†’ ì¦‰ì‹œ ë¯¸íŒ… íŒë‹¨ = NO
  â†’ STAGE 2ëŠ” ìˆ˜í–‰í•˜ì§€ ì•ŠëŠ”ë‹¤.

### STAGE 1 í•µì‹¬ ì² í•™
â€œì´ IRì€ íˆ¬ììë¥¼ ì„¤ë“í•  ë…¼ë¦¬ êµ¬ì¡°ë¥¼ ê°–ì¶”ì—ˆëŠ”ê°€?â€

### ë³´ìˆ˜ì  ê°ì  ê·œì¹™ (ë°˜ë“œì‹œ ì ìš©)
- â€˜í˜ì‹ ì â€™, â€˜ì„¸ê³„ ìµœì´ˆâ€™ ë“± ì¶”ìƒì  í˜•ìš©ì‚¬ ë‚¨ë°œ â†’ ë…¼ë¦¬ ëª¨í˜¸ì„±ìœ¼ë¡œ ê°ì 
- TAMë§Œ í‚¤ìš°ê³  SOM(ì‹¤ì œ í•´ê²° ê°€ëŠ¥ ë²”ìœ„)ì´ ë¶ˆëª…í™• â†’ ê°ì 
- ì£¼ì¥ê³¼ ë°ì´í„°ê°€ 1:1ë¡œ ë§¤ì¹­ë˜ì§€ ì•ŠìŒ â†’ í—ˆìœ„ ë…¼ë¦¬ë¡œ ê°„ì£¼

### STAGE 1 í‰ê°€ ê´€ì 
ë‹¤ìŒ ìš”ì†Œë¥¼ ë…¼ë¦¬ì  ì—­í•  ì¤‘ì‹¬ìœ¼ë¡œ í‰ê°€í•œë‹¤.
- ë¬¸ì œ ì •ì˜ê°€ ëˆ„êµ¬ì—ê²Œ, ì™œ, ì–¼ë§ˆë‚˜ ì¤‘ìš”í•œì§€ êµ¬ì²´ì ì¸ê°€
- ë¬¸ì œ â†’ ì†”ë£¨ì…˜ ì—°ê²°ì´ ê¸°ëŠ¥ ë‚˜ì—´ì´ ì•„ë‹Œ í•´ê²° ë©”ì»¤ë‹ˆì¦˜ì¸ê°€
- ì£¼ì¥ â†’ ê·¼ê±° â†’ ê²°ë¡ ì´ 1:1ë¡œ ì—°ê²°ë˜ëŠ”ê°€
- ë…¼ë¦¬ì  ë¹„ì•½ì´ ì¡´ì¬í•˜ëŠ”ê°€, ìˆë‹¤ë©´ ì¸ì‹Â·ê´€ë¦¬ë˜ëŠ”ê°€
- ìŠ¤í† ë¦¬ íë¦„ì´ ì¼ê´€ì ì¸ê°€ (Problem â†’ Solution â†’ Market â†’ BM â†’ Growth)
- íˆ¬ìì ì§ˆë¬¸(Why now / Why you / Why this way)ì„ ì„ ì œì ìœ¼ë¡œ ë‹µí•˜ëŠ”ê°€
- í•µì‹¬ ë©”ì‹œì§€ê°€ ì‘ì§‘ë˜ì–´ í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½ ê°€ëŠ¥í•œê°€

---

## [STAGE 2] ì‚°ì—… Ã— íˆ¬ìë‹¨ê³„ Ã— ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸ ì í•©ì„± í‰ê°€ (RELATIVE / BONUS)

STAGE 1ì„ í†µê³¼í•œ ê¸°ì—…ë§Œ ìˆ˜í–‰í•œë‹¤.

- íˆ¬ìë‹¨ê³„ ì í•©ì„±: 0â€“10
- ì‚°ì—… ì í•©ì„±: 0â€“10
- ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸ ì í•©ì„±: 0â€“10
- ì´ì : 0â€“30
- ê¸°ì¤€ì (í‰ê· ): 5ì 


---

### STAGE 2 ê³µí†µ ì ìˆ˜ í•´ì„
- 8â€“10ì : ëª…í™•íˆ ìš°ìˆ˜ (ë²¤ì¹˜ë§ˆí¬ ìƒíšŒ Hard Data)
- 5â€“7ì : í‰ê·  ìˆ˜ì¤€ (ê°€ì„¤ì€ í•©ë¦¬ì ì´ë‚˜ ê²€ì¦ ì‹œê³„ì—´ ë¶€ì¡±)
- 0â€“4ì : ë¯¸ë‹¬ (í•´ë‹¹ ì¡°ê±´ì—ì„œ ë‹¹ì—°íˆ ìˆì–´ì•¼ í•  ì¦ê±° ëˆ„ë½)

---

### [A] íˆ¬ì ë‹¨ê³„ë³„ ê¸°ëŒ€ ì¦ê±°

#### Seed / Pre-Seed
í•µì‹¬ ì§ˆë¬¸:
â€œê·¼ê±° ì—†ëŠ” ìì‹ ê°ì¸ê°€, ì•„ë‹ˆë©´ ëˆì´ ë˜ëŠ” ë¹„ë°€(Earned Secret)ì„ ì•Œê³  ìˆëŠ”ê°€?â€

í•„ìˆ˜ ì¦ê±°(ì—†ìœ¼ë©´ 3ì  ì´í•˜):
- Earned Secret (í˜„ì¥ì—ì„œë§Œ ì–»ì€ ë¬¸ì œ ì¸ì‚¬ì´íŠ¸)
- Founder-Market Fit
- ì†Œìˆ˜ë¼ë„ ì—´ê´‘í•˜ëŠ” ì´ˆê¸° ì‚¬ìš©ì ì‹ í˜¸

---

#### Series A
í•µì‹¬ ì§ˆë¬¸:
â€œë§ˆì¼€íŒ…ë¹„ë¡œ ë§Œë“  ê°€ì§œ ì„±ì¥ì´ ì•„ë‹Œê°€?â€

í•„ìˆ˜ ì¦ê±°(ì—†ìœ¼ë©´ 3ì  ì´í•˜):
- LTV/CAC â‰¥ 3
- ì½”í˜¸íŠ¸ ê¸°ë°˜ ë¦¬í…ì…˜
- GTM íš¨ìœ¨ì˜ ì‹œê³„ì—´ ê°œì„ 

---

#### Series B+
í•µì‹¬ ì§ˆë¬¸:
â€œê·œëª¨ê°€ ì»¤ì§ˆìˆ˜ë¡ ì´ìµë„ ì»¤ì§€ëŠ”ê°€?â€

í•„ìˆ˜ ì¦ê±°(ì—†ìœ¼ë©´ 3ì  ì´í•˜):
- NRR â‰¥ 110%
- ìš´ì˜ ë ˆë²„ë¦¬ì§€ ì¡´ì¬
- êµ¬ì¡°ì  ëª¨íŠ¸

---

### [B] ì‚°ì—…ë³„ ë³´ìˆ˜ì  ì£ëŒ€

#### SaaS / ê¸°ìˆ  / í”Œë«í¼
- Churn < 3%
- CAC Payback < 8~12ê°œì›”
- ìì²´ ë°ì´í„°/ì—”ì§„ ì—¬ë¶€

#### ì»¤ë¨¸ìŠ¤ / ë§ˆì¼“í”Œë ˆì´ìŠ¤
- CM2 í‘ì ì—¬ë¶€
- 3ê°œì›” ì¬êµ¬ë§¤ìœ¨ ì—…ê³„ í‰ê·  ëŒ€ë¹„ 1.5ë°°

#### ë°”ì´ì˜¤ / í—¬ìŠ¤ì¼€ì–´ / ë”¥í…Œí¬
- ê·œì œ/ê¸‰ì—¬ ë¡œë“œë§µ ëª…í™•ì„±
- ë¹„êµ ì„ìƒ/ì‹¤í—˜ ë°ì´í„°

---

### [C] ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸ë³„ í•µì‹¬ íŒë‹¨
- êµ¬ë…í˜•: ë¦¬í…ì…˜, NRR, ë‹¨ìœ„ê²½ì œì„±
- ê±°ë˜í˜•: GMV Ã— ë¹ˆë„ Ã— ë§ˆì§„
- ê´‘ê³ í˜•: ì°¸ì—¬ë„, ARPU, ë„¤íŠ¸ì›Œí¬ íš¨ê³¼
- ë¼ì´ì„ ìŠ¤: ê³„ì•½ êµ¬ì¡°, ë§ˆì¼ìŠ¤í†¤
- í•˜ë“œì›¨ì–´: ì›ê°€, ë§ˆì§„, ìŠ¤ì¼€ì¼ êµ¬ì¡°
"""


def get_api_key() -> str:
    api_key = st.secrets.get("gemini", {}).get("api_key")
    if not api_key:
        raise RuntimeError("Missing gemini api key in Streamlit secrets")
    return api_key


def kst_now() -> str:
    kst = tz.gettz("Asia/Seoul")
    return datetime.now(tz=kst).strftime("%Y-%m-%d %H:%M:%S")


def cache_key_for(content: str, step1_hash: str, step2_hash: str) -> str:
    parts = [md5_text(content), step1_hash, step2_hash, MODEL_NAME]
    return hashlib.sha256("::".join(parts).encode("utf-8")).hexdigest()


DEFAULT_WEIGHTS = {
    "ë¬¸ì œì •ì˜": 0.125,
    "ì†”ë£¨ì…˜&ì œí’ˆ": 0.125,
    "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.125,
    "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.125,
    "ê²½ìŸë¶„ì„": 0.125,
    "ì„±ì¥ì „ëµ": 0.125,
    "ì£¼ìš” ì¸ë ¥&íŒ€": 0.125,
    "ì¬ë¬´ê³„íš": 0.125,
}

STAGE_WEIGHTS = {
    "Seed": {
        "ë¬¸ì œì •ì˜": 0.18,
        "ì†”ë£¨ì…˜&ì œí’ˆ": 0.18,
        "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.12,
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.10,
        "ê²½ìŸë¶„ì„": 0.08,
        "ì„±ì¥ì „ëµ": 0.10,
        "ì£¼ìš” ì¸ë ¥&íŒ€": 0.16,
        "ì¬ë¬´ê³„íš": 0.08,
    },
    "Pre-Seed": {
        "ë¬¸ì œì •ì˜": 0.19,
        "ì†”ë£¨ì…˜&ì œí’ˆ": 0.18,
        "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.12,
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.08,
        "ê²½ìŸë¶„ì„": 0.08,
        "ì„±ì¥ì „ëµ": 0.10,
        "ì£¼ìš” ì¸ë ¥&íŒ€": 0.17,
        "ì¬ë¬´ê³„íš": 0.08,
    },
    "Series A": {
        "ë¬¸ì œì •ì˜": 0.10,
        "ì†”ë£¨ì…˜&ì œí’ˆ": 0.12,
        "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.18,
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.16,
        "ê²½ìŸë¶„ì„": 0.10,
        "ì„±ì¥ì „ëµ": 0.16,
        "ì£¼ìš” ì¸ë ¥&íŒ€": 0.10,
        "ì¬ë¬´ê³„íš": 0.08,
    },
    "Series B+": {
        "ë¬¸ì œì •ì˜": 0.08,
        "ì†”ë£¨ì…˜&ì œí’ˆ": 0.10,
        "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.14,
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.20,
        "ê²½ìŸë¶„ì„": 0.14,
        "ì„±ì¥ì „ëµ": 0.16,
        "ì£¼ìš” ì¸ë ¥&íŒ€": 0.08,
        "ì¬ë¬´ê³„íš": 0.10,
    },
}

INDUSTRY_WEIGHTS = {
    "SaaS": {
        "ë¬¸ì œì •ì˜": 0.10,
        "ì†”ë£¨ì…˜&ì œí’ˆ": 0.12,
        "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.18,
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.18,
        "ê²½ìŸë¶„ì„": 0.14,
        "ì„±ì¥ì „ëµ": 0.14,
        "ì£¼ìš” ì¸ë ¥&íŒ€": 0.08,
        "ì¬ë¬´ê³„íš": 0.06,
    },
    "Commerce": {
        "ë¬¸ì œì •ì˜": 0.10,
        "ì†”ë£¨ì…˜&ì œí’ˆ": 0.10,
        "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.18,
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.20,
        "ê²½ìŸë¶„ì„": 0.12,
        "ì„±ì¥ì „ëµ": 0.16,
        "ì£¼ìš” ì¸ë ¥&íŒ€": 0.08,
        "ì¬ë¬´ê³„íš": 0.06,
    },
    "Bio-Healthcare": {
        "ë¬¸ì œì •ì˜": 0.16,
        "ì†”ë£¨ì…˜&ì œí’ˆ": 0.18,
        "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.12,
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.10,
        "ê²½ìŸë¶„ì„": 0.10,
        "ì„±ì¥ì „ëµ": 0.10,
        "ì£¼ìš” ì¸ë ¥&íŒ€": 0.14,
        "ì¬ë¬´ê³„íš": 0.10,
    },
    "DeepTech": {
        "ë¬¸ì œì •ì˜": 0.14,
        "ì†”ë£¨ì…˜&ì œí’ˆ": 0.20,
        "ì‹œì¥ê·œëª¨&ë¶„ì„": 0.12,
        "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸": 0.10,
        "ê²½ìŸë¶„ì„": 0.12,
        "ì„±ì¥ì „ëµ": 0.10,
        "ì£¼ìš” ì¸ë ¥&íŒ€": 0.14,
        "ì¬ë¬´ê³„íš": 0.08,
    },
}


def _normalize_weights(weights: Dict[str, float]) -> Dict[str, float]:
    total = sum(weights.values()) or 1.0
    return {k: v / total for k, v in weights.items()}


def _combine_weights(stage_label: str, industry_label: str) -> Dict[str, float]:
    stage_weights = STAGE_WEIGHTS.get(stage_label, DEFAULT_WEIGHTS)
    industry_weights = INDUSTRY_WEIGHTS.get(industry_label, DEFAULT_WEIGHTS)
    combined = {}
    for key in ITEM_KEYS:
        combined[key] = (DEFAULT_WEIGHTS[key] + stage_weights[key] + industry_weights[key]) / 3.0
    return _normalize_weights(combined)


def _weighted_item_score(step1: Dict[str, Any], step2: Optional[Dict[str, Any]]) -> float:
    items = step1.get("item_evaluations", {}) if isinstance(step1, dict) else {}
    stage_label = ""
    industry_label = ""
    if step2 and isinstance(step2, dict):
        stage_label = str(step2.get("stage_label", "") or "")
        industry_label = str(step2.get("industry_label", "") or "")
    weights = _combine_weights(stage_label, industry_label)
    total = 0.0
    for key in ITEM_KEYS:
        item = items.get(key, {})
        try:
            score = float(item.get("score", 0) or 0)
        except (TypeError, ValueError):
            score = 0.0
        total += score * weights[key]
    return max(0.0, min(10.0, total)) * 10.0


def compute_perspective_scores(step1: Dict[str, Any], step2: Optional[Dict[str, Any]]) -> Dict[str, int]:
    logic_score = float(step1.get("logic_score", 0) or 0)
    if step2:
        stage = float(step2.get("stage_score", 0) or 0)
        industry = float(step2.get("industry_score", 0) or 0)
        bm = float(step2.get("bm_score", 0) or 0)
        normalized_step2 = (stage + industry + bm) / 30.0 * 100.0
    else:
        normalized_step2 = 0.0
    weighted_items = _weighted_item_score(step1, step2)
    base = 0.5 * logic_score + 0.3 * weighted_items + 0.2 * normalized_step2
    critical = base - 6
    neutral = base
    positive = base + 6
    return {
        "critical": min(92, int(round(max(0, critical)))),
        "neutral": min(92, int(round(max(0, neutral)))),
        "positive": min(92, int(round(max(0, positive)))),
    }


def recommendation_for(score: int) -> str:
    if score >= 80:
        return "ì¶”ì²œ"
    if score >= 70:
        return "ì¡°ê±´ë¶€ ê¶Œì¥"
    return "ë³´ë¥˜"


def derive_recommendations(scores: Dict[str, int]) -> Dict[str, str]:
    return {k: recommendation_for(v) for k, v in scores.items()}


def format_error_info(exc: Exception, file_name: str) -> Dict[str, str]:
    message = str(exc).replace("\n", " ")[:300]
    return {
        "type": exc.__class__.__name__,
        "message": message,
        "file_name": file_name,
    }


def evaluate_one(
    evaluator: Evaluator,
    content: str,
    file_name: str,
    step1_hash: str,
    step2_hash: str,
    force_rerun: bool,
    cache: Dict[str, Any],
) -> Dict[str, Any]:
    key = cache_key_for(content, step1_hash, step2_hash)
    if key in cache and not force_rerun:
        return {"status": STATUS_SKIPPED, "cache": cache[key], "file_name": file_name}

    step1_json = evaluator.evaluate_step1(
        content=content,
        prompt_step1=f"{BASE_PROMPT}\n\n{PROMPT_APPENDIX}",
        schema_hint_step1=to_json(STEP1_SCHEMA_HINT),
    )
    logic_score = float(step1_json.get("logic_score", 0) or 0)
    step1_json["pass_gate"] = logic_score >= 80

    step2_json: Optional[Dict[str, Any]] = None
    if step1_json.get("pass_gate", False):
        step2_json = evaluator.evaluate_step2(
            content=content,
            prompt_step2=f"{BASE_PROMPT}\n\n{PROMPT_APPENDIX}",
            schema_hint_step2=to_json(STEP2_SCHEMA_HINT),
            step1_json=step1_json,
        )

    scores = compute_perspective_scores(step1_json, step2_json)
    recommendations = derive_recommendations(scores)
    final_verdict = recommendations.get("critical", "ë³´ë¥˜")
    report_md = render_report(
        file_name,
        step1_json,
        step2_json,
        scores,
        recommendations,
        final_verdict,
    )

    result_payload = {
        "file_name": file_name,
        "timestamp": kst_now(),
        "company_name": step1_json.get("company_name", ""),
        "company_description": step1_json.get("one_line_summary", ""),
        "scores": scores,
        "recommendations": recommendations,
        "final_verdict": final_verdict,
        "overall_summary": step1_json.get("overall_summary", ""),
        "item_evaluations": step1_json.get("item_evaluations", {}),
        "strengths": step1_json.get("strengths", {}),
        "weaknesses": step1_json.get("weaknesses", {}),
        "red_flags": step1_json.get("red_flags", []),
        "axis_scores": {
            "stage": step2_json.get("stage_score") if step2_json else "",
            "industry": step2_json.get("industry_score") if step2_json else "",
            "bm": step2_json.get("bm_score") if step2_json else "",
        },
        "axis_comments": step2_json.get("axis_comments") if step2_json else {},
        "validation_questions": step2_json.get("validation_questions") if step2_json else {},
        "step1_json": step1_json,
        "step2_json": step2_json,
    }

    cache_entry = {
        "file_name": file_name,
        "timestamp": kst_now(),
        "step1": step1_json,
        "step2": step2_json,
        "report_md": report_md,
        "result_json": result_payload,
        "perspective_scores": scores,
        "recommendations": recommendations,
        "final_verdict": final_verdict,
        "status": STATUS_DONE,
        "cache_key": key,
    }
    cache[key] = cache_entry
    return {"status": STATUS_DONE, "cache": cache_entry, "file_name": file_name}


def build_sheet_row(entry: Dict[str, Any]) -> Dict[str, Any]:
    step1 = entry.get("step1", {})
    scores = entry.get("perspective_scores", {})
    recommendations = entry.get("recommendations", {})
    step2 = entry.get("step2", {})
    return {
        "timestamp(KST)": entry.get("timestamp", kst_now()),
        "file_name": entry.get("file_name", ""),
        "company_name": step1.get("company_name", ""),
        "company_description": step1.get("one_line_summary", ""),
        "score_critical": scores.get("critical", ""),
        "score_neutral": scores.get("neutral", ""),
        "score_positive": scores.get("positive", ""),
        "recommendation_critical": recommendations.get("critical", ""),
        "recommendation_neutral": recommendations.get("neutral", ""),
        "recommendation_positive": recommendations.get("positive", ""),
        "overall_summary": step1.get("overall_summary", ""),
        "item_evaluations_json": json.dumps(step1.get("item_evaluations", {}), ensure_ascii=True),
        "strengths_json": json.dumps(step1.get("strengths", {}), ensure_ascii=True),
        "weaknesses_json": json.dumps(step1.get("weaknesses", {}), ensure_ascii=True),
        "red_flags_json": json.dumps(step1.get("red_flags", []), ensure_ascii=True),
        "axis_scores_json": json.dumps(
            {
                "stage": step2.get("stage_score", "") if isinstance(step2, dict) else "",
                "industry": step2.get("industry_score", "") if isinstance(step2, dict) else "",
                "bm": step2.get("bm_score", "") if isinstance(step2, dict) else "",
            },
            ensure_ascii=True,
        ),
        "axis_comments_json": json.dumps(step2.get("axis_comments", {}) if isinstance(step2, dict) else {}, ensure_ascii=True),
        "validation_questions_json": json.dumps(
            step2.get("validation_questions", {}) if isinstance(step2, dict) else {}, ensure_ascii=True
        ),
        "final_verdict": entry.get("final_verdict", ""),
    }


def cache_to_excel_bytes(cache: Dict[str, Any]) -> bytes:
    wb = openpyxl.Workbook()
    ws = wb.active
    ws.title = "IR_EVAL"
    ws.append(SHEET_COLUMNS)
    for entry in cache.values():
        row = build_sheet_row(entry)
        ws.append([row.get(col, "") for col in SHEET_COLUMNS])
    buffer = BytesIO()
    wb.save(buffer)
    return buffer.getvalue()


def excel_filename() -> str:
    stamp = datetime.utcnow().strftime("%Y%m%d_%H%M")
    return f"ir_eval_{stamp}.xlsx"


def status_badge(status: str) -> str:
    mapping = {
        STATUS_DONE: "âœ…ì™„ë£Œ",
        STATUS_PENDING: "ğŸ•’ëŒ€ê¸°",
        STATUS_FAILED: "âš ï¸ì‹¤íŒ¨",
        STATUS_RUNNING: "ğŸ”„ì§„í–‰ì¤‘",
        STATUS_SKIPPED: "âœ…ì™„ë£Œ",
    }
    return mapping.get(status, status or "-")


def render_preview_panel(entry: Optional[Dict[str, Any]]) -> None:
    st.subheader("ë¯¸ë¦¬ë³´ê¸°")
    if not entry:
        st.info("ì„ íƒëœ ë¦¬í¬íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    step1 = entry.get("step1", {})
    scores = entry.get("perspective_scores", {})
    company_name = step1.get("company_name") or "ê¸°ì—…ëª… ë¯¸ìƒ"
    st.markdown(
        f"""
        <div class="preview-card">
          <div class="preview-title">ë¦¬í¬íŠ¸ ì œëª© : {company_name}</div>
          <div class="preview-sub">Critical : {scores.get('critical','')} &nbsp;&nbsp;
          Neutral : {scores.get('neutral','')} &nbsp;&nbsp;
          Positive : {scores.get('positive','')}</div>
          <div style="margin-top:0.6rem;">{step1.get("one_line_summary", "")}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    st.markdown(
        f"""
        <div class="preview-card">
          <div class="preview-title">Title : ì¢…í•© í‰ê°€</div>
          <div>{step1.get("overall_summary", "(ì—†ìŒ)")}</div>
        </div>
        """,
        unsafe_allow_html=True,
    )

    item_evaluations = step1.get("item_evaluations", {})
    if not item_evaluations:
        st.info("í•­ëª©ë³„ í‰ê°€ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    st.markdown("### í•­ëª©ë³„ í‰ê°€")
    for i in range(0, len(ITEM_KEYS), 2):
        cols = st.columns(2)
        for j, key in enumerate(ITEM_KEYS[i : i + 2]):
            value = item_evaluations.get(key, {})
            comment = value.get("comment", "")
            feedback = value.get("feedback", "")
            cols[j].markdown(
                f"""
                <div class="preview-card">
                  <div class="preview-title">Title : {key}</div>
                  <div>{comment or "(ì½”ë©˜íŠ¸ ì—†ìŒ)"}</div>
                  <div style="margin-top:0.5rem;">{feedback or "(í”¼ë“œë°± ì—†ìŒ)"}</div>
                </div>
                """,
                unsafe_allow_html=True,
            )
            text = f"{comment} {feedback}".strip()
            sentences = [s for s in re.split(r"[.!?]\s+", text) if s.strip()]
            if len(sentences) < 6:
                cols[j].caption("ê¶Œì¥ ë¶„ëŸ‰: comment 5~8ë¬¸ì¥, feedback 4~5ë¬¸ì¥")


def init_session_state() -> None:
    st.session_state.setdefault("files", [])
    st.session_state.setdefault("cache", {})
    st.session_state.setdefault("status_map", {})
    st.session_state.setdefault("selected_file_ids", [])
    st.session_state.setdefault("selected_file_name", "")
    st.session_state.setdefault("page", 1)


def main() -> None:
    st.set_page_config(page_title="IR Evaluator", layout="wide")
    st.markdown(
        """
        <style>
        .block-container { padding-top: 1.2rem; padding-bottom: 1.6rem; }
        .table-header { font-weight: 700; color: #2b2b2b; font-size: 0.95rem; }
        .muted { color: #6b7280; font-size: 0.85rem; }
        .compact .stButton>button { padding: 0.25rem 0.6rem; font-size: 0.85rem; }
        .compact .stCheckbox { padding-top: 0.2rem; }
        .compact .stTextInput>div>div>input { height: 2rem; }
        .compact .stFileUploader { padding-bottom: 0.2rem; }
        .compact .stMarkdown { margin-bottom: 0.15rem; }
        .row-compact { font-size: 0.88rem; }
        .preview-card {
            border: 1px solid #e5e7eb;
            border-radius: 10px;
            padding: 0.8rem 0.9rem;
            background: #fafafa;
            margin-bottom: 0.7rem;
        }
        .preview-title { font-weight: 700; margin-bottom: 0.4rem; }
        .preview-sub { color: #6b7280; font-size: 0.85rem; }
        </style>
        """,
        unsafe_allow_html=True,
    )

    st.title("IR ë¶„ì„ & í‰ê°€")

    try:
        api_key = get_api_key()
    except RuntimeError as exc:
        st.error(str(exc))
        st.stop()

    init_session_state()

    st.markdown("<div class='compact'>", unsafe_allow_html=True)
    top_cols = st.columns([5, 1, 1, 1, 1], gap="small")
    with top_cols[0]:
        uploaded_files = st.file_uploader(
            "IR Markdown ì—…ë¡œë“œ (.md)",
            type=["md"],
            accept_multiple_files=True,
            label_visibility="visible",
        )
    with top_cols[1]:
        scan_clicked = st.button("ë¬¸ì„œ ìŠ¤ìº”", use_container_width=True)
    with top_cols[2]:
        force_rerun = st.checkbox("ìºì‹œ ë¬´ì‹œ(ì¬í‰ê°€)", value=False)
    with top_cols[3]:
        refresh_clicked = st.button("ìºì‹œ ìƒˆë¡œê³ ì¹¨", use_container_width=True)
    with top_cols[4]:
        delete_cache_clicked = st.button("ìºì‹œ ì‚­ì œ", use_container_width=True)
    st.markdown("</div>", unsafe_allow_html=True)

    if refresh_clicked:
        st.session_state["status_map"] = st.session_state.get("status_map", {})

    if delete_cache_clicked:
        st.session_state["cache"] = {}
        st.session_state["status_map"] = {}

    if scan_clicked and uploaded_files:
        st.session_state["files"] = uploaded_files
        st.session_state["status_map"] = {f.name: STATUS_PENDING for f in uploaded_files}

    files = st.session_state.get("files", [])
    if not files:
        st.info("íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ .md íŒŒì¼ ëª©ë¡ì´ ë‚˜íƒ€ë‚©ë‹ˆë‹¤.")
        return

    table_header = st.columns([3, 1], gap="small")
    table_header[0].subheader("íŒŒì¼ ëª©ë¡ & IR List")
    if st.session_state.get("cache"):
        excel_bytes = cache_to_excel_bytes(st.session_state["cache"])
        table_header[1].download_button(
            label="ì—‘ì…€ ë‹¤ìš´ë¡œë“œ",
            data=excel_bytes,
            file_name=excel_filename(),
            mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
            use_container_width=True,
        )
    else:
        table_header[1].button("ì—‘ì…€ ë‹¤ìš´ë¡œë“œ", disabled=True, use_container_width=True)

    st.markdown("<div class='compact'>", unsafe_allow_html=True)
    search_term = st.text_input("ê²€ìƒ‰(íŒŒì¼ëª…/ê¸°ì—…ëª…)", value="", placeholder="íŒŒì¼ëª… ë˜ëŠ” ê¸°ì—…ëª…")
    st.markdown("</div>", unsafe_allow_html=True)

    header_cols = st.columns([3, 1, 0.8, 1.2, 1, 1, 1, 1, 1], gap="small")
    header_cols[0].markdown("<div class='table-header'>íŒŒì¼ëª…</div>", unsafe_allow_html=True)
    header_cols[1].markdown("<div class='table-header'>ì§„í–‰</div>", unsafe_allow_html=True)
    header_cols[2].markdown("<div class='table-header'>ì„ íƒ</div>", unsafe_allow_html=True)
    header_cols[3].markdown("<div class='table-header'>ê¸°ì—…ëª…</div>", unsafe_allow_html=True)
    header_cols[4].markdown("<div class='table-header'>critical</div>", unsafe_allow_html=True)
    header_cols[5].markdown("<div class='table-header'>neutral</div>", unsafe_allow_html=True)
    header_cols[6].markdown("<div class='table-header'>positive</div>", unsafe_allow_html=True)
    header_cols[7].markdown("<div class='table-header'>ë¯¸ë¦¬ë³´ê¸°</div>", unsafe_allow_html=True)
    header_cols[8].markdown("<div class='table-header'>íŒŒì¼ì—´ê¸°</div>", unsafe_allow_html=True)

    selected_ids = set(st.session_state.get("selected_file_ids", []))
    cache = st.session_state.get("cache", {})
    cache_by_name = {entry.get("file_name", ""): entry for entry in cache.values()}
    status_map = st.session_state.get("status_map", {})
    for f in files:
        entry = cache_by_name.get(f.name)
        if not entry:
            continue
        cached_status = entry.get("status", STATUS_DONE)
        if status_map.get(f.name) != cached_status:
            status_map[f.name] = cached_status
    st.session_state["status_map"] = status_map

    filtered_files = []
    for f in files:
        entry = cache_by_name.get(f.name)
        company_name = entry.get("step1", {}).get("company_name", "") if entry else ""
        if search_term:
            term = search_term.strip().lower()
            if term not in f.name.lower() and term not in company_name.lower():
                continue
        filtered_files.append(f)

    page_size = 10
    total_pages = max(1, (len(filtered_files) + page_size - 1) // page_size)
    page = min(st.session_state.get("page", 1), total_pages)
    pager_cols = st.columns([1, 1, 2, 1, 1], gap="small")
    if pager_cols[0].button("ì´ì „", use_container_width=True):
        page = max(1, page - 1)
    pager_cols[2].markdown(f"<div class='muted'>í˜ì´ì§€ {page}/{total_pages}</div>", unsafe_allow_html=True)
    if pager_cols[4].button("ë‹¤ìŒ", use_container_width=True):
        page = min(total_pages, page + 1)
    st.session_state["page"] = page

    start = (page - 1) * page_size
    end = start + page_size
    for f in filtered_files[start:end]:
        entry = cache_by_name.get(f.name)
        company_name = entry.get("step1", {}).get("company_name", "") if entry else ""
        scores = entry.get("perspective_scores", {}) if entry else {}

        row = st.columns([3, 1, 0.8, 1.2, 1, 1, 1, 1, 1], gap="small")
        row[0].markdown(f"<div class='row-compact'>{f.name}</div>", unsafe_allow_html=True)
        row[1].markdown(
            f"<div class='row-compact'>{status_badge(st.session_state['status_map'].get(f.name, STATUS_PENDING))}</div>",
            unsafe_allow_html=True,
        )
        checked = row[2].checkbox(
            "",
            value=f.name in selected_ids,
            key=f"select_{f.name}",
        )
        if checked:
            selected_ids.add(f.name)
        else:
            selected_ids.discard(f.name)
        row[3].markdown(f"<div class='row-compact'>{company_name}</div>", unsafe_allow_html=True)
        row[4].markdown(f"<div class='row-compact'>{scores.get('critical', '')}</div>", unsafe_allow_html=True)
        row[5].markdown(f"<div class='row-compact'>{scores.get('neutral', '')}</div>", unsafe_allow_html=True)
        row[6].markdown(f"<div class='row-compact'>{scores.get('positive', '')}</div>", unsafe_allow_html=True)
        if row[7].button("ë³´ê¸°", key=f"preview_{f.name}") and entry:
            st.session_state["selected_file_name"] = f.name
        report_text = entry.get("report_md", "") if entry else ""
        row[8].download_button(
            label="íŒŒì¼ì—´ê¸°",
            data=report_text or "",
            file_name=f"{f.name}.report.md",
            mime="text/markdown",
            key=f"dl_{f.name}",
            use_container_width=True,
        )

    st.session_state["selected_file_ids"] = list(selected_ids)

    st.markdown("<div class='compact'>", unsafe_allow_html=True)
    action_cols = st.columns([5, 1, 1, 1, 1], gap="small")
    action_cols[0].markdown("<div class='muted'>ì„ íƒ í›„ í‰ê°€ë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.</div>", unsafe_allow_html=True)
    evaluate_selected = action_cols[1].button("ì„ íƒ í‰ê°€", use_container_width=True)
    evaluate_all = action_cols[2].button("ì „ì²´ í‰ê°€", use_container_width=True)
    load_history = action_cols[3].button("íˆìŠ¤í† ë¦¬", use_container_width=True)
    st.markdown("</div>", unsafe_allow_html=True)

    evaluator = Evaluator(api_key=api_key, semaphore=threading.Semaphore(2))
    prompt_step1 = BASE_PROMPT
    prompt_step2 = BASE_PROMPT
    step1_hash = hash_prompt(prompt_step1)
    step2_hash = hash_prompt(prompt_step2)

    if evaluate_selected or evaluate_all:
        target_files = filtered_files if evaluate_all else [f for f in files if f.name in selected_ids]
        if not target_files:
            st.warning("í‰ê°€í•  íŒŒì¼ì„ ì„ íƒí•˜ì„¸ìš”.")
            return

        results: List[Dict[str, Any]] = []
        failures: List[Dict[str, str]] = []
        progress = st.progress(0)
        progress_text = st.empty()
        completed = 0

        def run_file(file_obj):
            content = file_obj.getvalue().decode("utf-8", errors="replace")
            return evaluate_one(
                evaluator,
                content,
                file_obj.name,
                step1_hash,
                step2_hash,
                force_rerun,
                cache,
            )

        with concurrent.futures.ThreadPoolExecutor(max_workers=10) as executor:
            future_to_file = {executor.submit(run_file, f): f for f in target_files}
            for future in concurrent.futures.as_completed(future_to_file):
                file_obj = future_to_file[future]
                try:
                    results.append(future.result())
                except Exception as exc:
                    error_info = format_error_info(exc, file_obj.name)
                    results.append(
                        {"status": STATUS_FAILED, "error": error_info, "file_name": file_obj.name}
                    )
                    failures.append(error_info)
                completed += 1
                progress.progress(completed / len(target_files))
                progress_text.write(f"ì§„í–‰: {completed}/{len(target_files)}")

        for res in results:
            file_name = res.get("file_name", "")
            if res.get("status") == STATUS_DONE:
                st.session_state["status_map"][file_name] = STATUS_DONE
            elif res.get("status") == STATUS_SKIPPED:
                st.session_state["status_map"][file_name] = STATUS_SKIPPED
            else:
                if file_name:
                    st.session_state["status_map"][file_name] = STATUS_FAILED

        if failures:
            st.error(
                "\n".join(
                    f"{f['file_name']} | {f['type']} | {f['message']}" for f in failures
                )
            )
        st.rerun()

    if load_history:
        st.info("ì„¸ì…˜ ìºì‹œ ê¸°ì¤€ìœ¼ë¡œ íˆìŠ¤í† ë¦¬ë¥¼ í‘œì‹œí•©ë‹ˆë‹¤.")

    selected_name = st.session_state.get("selected_file_name")
    entry = cache_by_name.get(selected_name) if selected_name else None
    render_preview_panel(entry)


if __name__ == "__main__":
    main()
